{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieVSM_NaVTDU"
      },
      "source": [
        "#Modelo de Machine Learning de Ponta a Ponta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adsLnldVXIPu"
      },
      "source": [
        "Depois que apresentamos as soluções para melhorar o desempenho da empresa e recuperar uma parte do faturamento, estamos prontos para criar um Modelo de Machine Learning capaz de prever a demanda para os próximos dias, gerando valor para os parceiros e levando informações preciosas para que eles possam se preparar para o dia de trabalho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4KJTld7xMu3"
      },
      "outputs": [],
      "source": [
        "#import das bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4rp2cIZyof2"
      },
      "source": [
        "## Análise de Estrutura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJjAbDBWVXI7"
      },
      "source": [
        "## Remoção de Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKHvsKN89Vi9"
      },
      "outputs": [],
      "source": [
        "#Leitura do csv\n",
        "df_orders = pd.read_csv(\"orders.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5018W-fu12t-"
      },
      "outputs": [],
      "source": [
        "#Corte de outliers\n",
        "df_orders = df_orders[(df_orders['order_amount'] >= 15) &\n",
        "          (df_orders['order_amount'] <= 200)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQQ9AhAmxbHm",
        "outputId": "dc39e617-b754-4858-eb4d-ec65cbca6df8"
      },
      "outputs": [],
      "source": [
        "#info\n",
        "df_orders.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1889SjWzJYH"
      },
      "source": [
        "## Novas Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_3JJnwIzPdD",
        "outputId": "4c709a04-3032-460a-a1b9-238fa7f00501"
      },
      "outputs": [],
      "source": [
        "#converter order_moment_created para data\n",
        "df_orders['order_moment_created'] = pd.to_datetime(df_orders['order_moment_created'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMgRI5OE1hIk"
      },
      "outputs": [],
      "source": [
        "#nova coluna com o dia da semana\n",
        "df_orders['day_of_week'] = df_orders['order_moment_created'].dt.day_of_week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "lPyiEvdJ5w2N",
        "outputId": "252be655-7e97-4ab6-9df8-0865fd271b60"
      },
      "outputs": [],
      "source": [
        "#Análise da quantidade de horas que temos pedidos por dia\n",
        "df_orders['order_created_hour'].value_counts() \\\n",
        "  .reset_index() \\\n",
        "  .sort_values('order_created_hour')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uw-f5H6Q6X7k",
        "outputId": "6971baa6-977f-4d82-e4e4-4507a8b50bb9"
      },
      "outputs": [],
      "source": [
        "#criando função por faixa de horário\n",
        "def faixa_horario(hora):\n",
        "  if hora >= 0 and hora <= 5:\n",
        "    return 'madrugada'\n",
        "  elif hora >= 6 and hora <= 10:\n",
        "    return 'manha'\n",
        "  elif hora >= 11 and hora <= 14:\n",
        "    return 'almoco'\n",
        "  elif hora >= 15 and hora <= 18:\n",
        "    return 'tarde'\n",
        "  else:\n",
        "    return 'noite'\n",
        "\n",
        "faixa_horario(19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "HhUb-QCe5aZ2",
        "outputId": "d673c48b-32c1-4b53-b77a-2e177305d07b"
      },
      "outputs": [],
      "source": [
        "#aplicando função e criando uma nova coluna com o nome de faixa de horário\n",
        "df_orders['faixa_horario'] = df_orders['order_created_hour'].apply(faixa_horario)\n",
        "df_orders['faixa_horario'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqQgnykXyruE"
      },
      "source": [
        "## DataPrep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5tzvIEo-giy"
      },
      "outputs": [],
      "source": [
        "#Criando um novo dataset de orders_treatment\n",
        "df_orders_tratamento = df_orders.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEE97xId3L-k",
        "outputId": "ea2ab65c-84a8-4f07-e5ed-2d76054f87e2"
      },
      "outputs": [],
      "source": [
        "#info\n",
        "df_orders_tratamento.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2YTy5rBFYlT"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-70KGa5-mDO"
      },
      "source": [
        "#### Exclusão de colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Osr4xOQV2l0M"
      },
      "outputs": [],
      "source": [
        "#após realizar análise das variáveis excluir variável order_moment_delivered\n",
        "df_orders_tratamento.drop('order_moment_delivered', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1SOA6Px3OpG"
      },
      "outputs": [],
      "source": [
        "#definição das colunas que serão excluídas da nossa base\n",
        "columns_delete = ['payment_order_id',\n",
        "'delivery_order_id',\n",
        "'order_created_minute',\n",
        "'order_created_month',\n",
        "'order_created_year',\n",
        "'order_moment_created',\n",
        "'order_moment_accepted',\n",
        "'order_moment_ready',\n",
        "'order_moment_collected',\n",
        "'order_moment_in_expedition',\n",
        "'order_moment_delivering',\n",
        "'order_moment_finished',\n",
        "'order_delivery_fee',\n",
        "'order_delivery_cost',\n",
        "'order_created_hour']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0jLXVK03v9X"
      },
      "outputs": [],
      "source": [
        "#excluir colunas\n",
        "df_orders_tratamento.drop(columns_delete, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLgeTuLD-paw"
      },
      "source": [
        "#### Prenchendo valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joDBi9FtWVSh",
        "outputId": "d54100f0-eb15-4d5e-af50-9db25a96c500"
      },
      "outputs": [],
      "source": [
        "#info\n",
        "df_orders_tratamento.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuOEJ3xHDBcZ",
        "outputId": "86d3af25-99ad-4340-b830-965319d918d5"
      },
      "outputs": [],
      "source": [
        "#utilização do fillna com a mediana para preencher os valores do order_metric_collected_time\n",
        "df_orders_tratamento['order_metric_collected_time'] \\\n",
        "  .fillna(df_orders_tratamento['order_metric_collected_time'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsPGBTq6u0bI",
        "outputId": "931cf0c6-34d3-4d47-98fb-8fa76cd9e1cb"
      },
      "outputs": [],
      "source": [
        "df_orders_tratamento.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDclaSBLEkbq"
      },
      "source": [
        "### Criação do dataset final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "BroxawKwBeb4",
        "outputId": "82aa2982-37b2-47d3-a05c-faccdbe2b97b"
      },
      "outputs": [],
      "source": [
        "#Criação do dataset final de grupos\n",
        "\"\"\"df_orders_treatment_group = df_orders_tratamento.groupby(['store_id', 'channel_id', 'order_created_day', 'day_of_week', 'faixa_horario']) \\\n",
        "  .agg({'order_metric_collected_time':'median',\n",
        "        'order_metric_paused_time':'median',\n",
        "        'order_metric_production_time':'median',\n",
        "        'order_metric_walking_time':'median',\n",
        "        'order_metric_expediton_speed_time':'median',\n",
        "        'order_metric_transit_time':'median',\n",
        "        'order_metric_cycle_time':'median',\n",
        "        'order_id':'count'}) \\\n",
        "  .reset_index() \\\n",
        "  .sort_values('order_id', ascending=False)\n",
        "\n",
        "df_orders_treatment_group=df_orders_treatment_group.rename(columns = {'order_id':'demanda'})\n",
        "\n",
        "df_orders_treatment_group.head()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNecbZgZ_iiX",
        "outputId": "b33e8d86-72b3-4a67-d4e5-0894a1bbc8f7"
      },
      "outputs": [],
      "source": [
        "#info\n",
        "df_orders_tratamento.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKw2IBKtEodf"
      },
      "source": [
        "### Criando um conjunto de testes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oqalSEkErkv"
      },
      "source": [
        "Antes de seguir adiante, vamos precisar criar um conjunto de teste, colocá-lo de lado e nunca checá-lo. <br/>\n",
        "\n",
        "Quando estimamos o erro de generalização utilizando o conjunto de teste, sua estimativa será muito otimista e será lançado um sistema que não funcionará tão bem quanto o esperado.  <br/>\n",
        "\n",
        "Isso é chamado de **data snooping bias.** <br/>\n",
        "\n",
        "O Scikit-Learn fornece algumas funções para dividir conjuntos de dados em vários subconjuntos de diversas maneiras. A função mais simples é train_test_split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHzKB3py_sG3"
      },
      "outputs": [],
      "source": [
        "#import do train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG3gTaR2Q5XY"
      },
      "outputs": [],
      "source": [
        "#Separa a base de treino e teste\n",
        "train_set, test_set = train_test_split(df_orders_tratamento,\n",
        "                                      test_size=0.2,\n",
        "                                      random_state=42)\n",
        "\n",
        "df_orders_train = train_set.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KESN2BGBVApy"
      },
      "outputs": [],
      "source": [
        "#Separa a Label principal\n",
        "df_orders_treatment_label = df_orders_train[['order_status']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq7j9Kc3VL-g"
      },
      "outputs": [],
      "source": [
        "#Remove a Label da base\n",
        "df_orders_treatment = df_orders_train.drop('order_status', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD4MyMloD5mw"
      },
      "outputs": [],
      "source": [
        "#Seleciona as variáveis float64\n",
        "df_float_64 = df_orders_treatment.select_dtypes(np.float64).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlPpXdTcDnHf"
      },
      "outputs": [],
      "source": [
        "#Import do SimpleImputer\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qp-NpFTDqHj"
      },
      "outputs": [],
      "source": [
        "#Adicionando estratégia da mediana no imputer\n",
        "imputer = SimpleImputer(strategy='median')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "XHgqdnrtEQjd",
        "outputId": "0a224593-3258-4170-b767-3ac12b2b44c8"
      },
      "outputs": [],
      "source": [
        "#Treina o imputer\n",
        "imputer.fit(df_float_64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25p7I6WhFJ3z"
      },
      "outputs": [],
      "source": [
        "#Cria nova matriz preenchendo os valores nulos com o imputer\n",
        "float_vars = imputer.transform(df_float_64)\n",
        "#float_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAu5FhBeFYWO",
        "outputId": "f801ae3c-833e-4ee9-a5bd-5cd3feb27952"
      },
      "outputs": [],
      "source": [
        "#Cria novo dataset para apresentar os valores\n",
        "df_64 = pd.DataFrame(float_vars, columns=df_float_64.columns,\n",
        "                     index=df_float_64.index)\n",
        "df_64.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JRumVFvC-Xs"
      },
      "source": [
        "## Seleção Final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwY0dcuLy5Ju"
      },
      "source": [
        "## Variáveis Categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esYV575hF758",
        "outputId": "4c08c442-73c4-4811-bdcb-655c42af98d9"
      },
      "outputs": [],
      "source": [
        "#info\n",
        "df_orders_treatment.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "D-QUpDRIGFU-",
        "outputId": "e8b7a336-5c46-4995-b060-dc7a8f2f8814"
      },
      "outputs": [],
      "source": [
        "#seleção de day_of_week e faixa_horario\n",
        "df_orders_treatment[['day_of_week', 'faixa_horario']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "jhUfHEZaGRwq",
        "outputId": "4ba6b194-117c-4c43-b279-03afac8844a4"
      },
      "outputs": [],
      "source": [
        "#value_counts faixa de horario\n",
        "df_orders_treatment['faixa_horario'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyBrO-NgWPM3"
      },
      "outputs": [],
      "source": [
        "#novo dataset com a seleção das variaveis numéricas categóricas\n",
        "df_orders_treatment_cat_num = df_orders_treatment[['store_id',\n",
        "                                                   'channel_id',\n",
        "                                                   'order_created_day',\n",
        "                                                   'day_of_week']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJOxsPD-GYO5"
      },
      "outputs": [],
      "source": [
        "#novo dataset com a seleção das variáveis categóricas\n",
        "df_orders_treatment_cat = df_orders_treatment[['faixa_horario']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_LUSah5GopW"
      },
      "outputs": [],
      "source": [
        "#import do OrdinalEncoder e do OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DgM52plFzYT"
      },
      "source": [
        "### Ordinal Encoder\n",
        "A maioria dos algoritmos de Aprendizado de Máquina prefere trabalhar com números, então vamos converter as categorias de texto para números. Para tanto, podemos utilizar o método OrdinalEncoder(), que mapeia cada categoria para um número inteiro diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRly-ClqGfDa",
        "outputId": "4dba4e7f-188c-4f98-b380-64fa706d890a"
      },
      "outputs": [],
      "source": [
        "#tratamento com o OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "df_orders_treatment_cat_encoded = ordinal_encoder.fit_transform(df_orders_treatment_cat)\n",
        "#df_orders_treatment_cat_encoded[:10]\n",
        "ordinal_encoder.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQRnqxB3GNt5"
      },
      "source": [
        "### OneHotEncoder\n",
        "O OrdinalEncoder pega a quantidade de atributos e converte em números, porém transformando puramente em números ele cria uma diferença de valores entre os números. As categorias 0 e 1 transformadas tem uma distância semelhante, não podemos dizer o mesmo para as categorias 0 e 2, os algoritmos de ML enxergarão essa escala como uma diferença significa entre os dados. <br/>\n",
        "A utilização do OneHotEncoder é melhor aproveitada para esses casos. Ela cria novos atributos de acordo com a quantidade de atributos com 0 e 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkooAI5-G8sR",
        "outputId": "2bac7c1d-8238-45b9-986e-546cd689d744"
      },
      "outputs": [],
      "source": [
        "#tratamento da categoria com o OneHotEncoder\n",
        "cat_encoder = OneHotEncoder()\n",
        "df_orders_treatment_cat_1hot = cat_encoder.fit_transform(df_orders_treatment_cat)\n",
        "cat_encoder.categories_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xdn9J15HFS0",
        "outputId": "75487c85-234c-4ed8-da35-5dad63e2180b"
      },
      "outputs": [],
      "source": [
        "#Visuaulização das categorias em array\n",
        "df_orders_treatment_cat_1hot.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKAFUfGDHJT7",
        "outputId": "1f4cdd6b-d86b-4a6e-eb4f-09d47ae4f24f"
      },
      "outputs": [],
      "source": [
        "#Visualização das categorias\n",
        "cat_encoder.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gP5xugHzlC0"
      },
      "source": [
        "## Escalonando nossos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "1BSwtH47XDD6",
        "outputId": "8ad2bca4-a037-4f09-d42b-2cf8078e49b3"
      },
      "outputs": [],
      "source": [
        "#visualização do df_float64\n",
        "df_64.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZeX408IXZBh"
      },
      "outputs": [],
      "source": [
        "#import do MinMaxScaler e do StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjazQhmnGWjt"
      },
      "source": [
        "### MinMaxScaler\n",
        "O escalonamento min-max (muitas pessoas chamam de normalização) é bastante simples: os valores são deslocados e redimensionados para que acabem variando de 0 a 1. Ele subtrai o valor mínimo e divide pelo máximo menos o mínimo. O Scikit-Learn fornece um transformador chamado MinMaxScaler para isso. Ele possui um hiper parâmetro feature_range que permite alterar o intervalo se não quiser 0-1 por algum motivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbz6ypOfXQy4"
      },
      "outputs": [],
      "source": [
        "#Tratamento com MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df_64)\n",
        "df_float64_transform = scaler.transform(df_64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4L6UwDpXbph",
        "outputId": "ee06ee26-30a3-4b51-a8ba-f9fd37f613eb"
      },
      "outputs": [],
      "source": [
        "#Visualiza transformação\n",
        "df_float64_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HKPHlK_XokM"
      },
      "source": [
        "### StandardScaler\n",
        "A padronização é bem diferente: em primeiro lugar ela subtrai o valor médio (assim os valores padronizados sempre têm média zero) e, em seguida, divide pela variância, de modo que a distribuição resultante tenha variância unitária.\n",
        "Ao contrário do escalonamento min-max, a padronização não vincula valores a um intervalo específico, o que pode ser um problema para alguns algoritmos.\n",
        "No entanto, a padronização é muito menos afetada por outliers.\n",
        "O Scikit-Learn fornece um transformador para padronização chamado StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhodSlMYXp8z"
      },
      "outputs": [],
      "source": [
        "#Tratamento com o SatandardScaler\n",
        "standard = StandardScaler()\n",
        "standard.fit(df_64)\n",
        "df_float64_transform_standard = standard.transform(df_64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aytL1XUlXzKW",
        "outputId": "2a828ad3-58f9-4173-812a-c2f715a26a05"
      },
      "outputs": [],
      "source": [
        "#Visualiza transformação\n",
        "df_float64_transform_standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mCzQpyecssN"
      },
      "source": [
        "**Quando usar cada um?**<br/>\n",
        "- MinMax Scaling é indicado quando a distribuição dos dados não segue uma gaussiana ou quando você sabe que as variáveis devem estar em um intervalo específico (ex.: redes neurais com funções de ativação como sigmoid).\n",
        "- Standard Scaling é mais indicado quando os dados têm uma distribuição aproximadamente normal e é necessário manter essa forma de distribuição."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xF-yUUzz0vc"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZZndJX7YbIT"
      },
      "outputs": [],
      "source": [
        "#import do Pipeline\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuqivqRTG4H7"
      },
      "source": [
        "Existem muitas etapas de transformação de dados que precisam ser executadas na ordem correta. Felizmente, o Scikit-Learn fornece a classe Pipeline para ajudar tais sequências de transformações.\n",
        "\n",
        "O construtor Pipeline se vale de uma lista de pares de nome/estimador que definem uma sequência de etapas. Todos, exceto o último estimador, devem ser transformadores (ou seja, eles devem ter um método fit_transform()).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GczkaZl3DU4b"
      },
      "source": [
        "### Pipeline Numérico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4uTVkPpYkAF"
      },
      "outputs": [],
      "source": [
        "#Criação do novo pipeline com o Imputer e StandardScaler\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slFec5ZHYt0g"
      },
      "outputs": [],
      "source": [
        "#Criação de um novo dataset com o pipline numérico\n",
        "orders_num_tr = num_pipeline.fit_transform(df_float_64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs3d1B-wY2oz",
        "outputId": "80d93961-dc84-498a-aaef-125216e21ce0"
      },
      "outputs": [],
      "source": [
        "#Apresentação do Shape da transformação após o pipeline\n",
        "orders_num_tr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPIbqzVNHE4p"
      },
      "source": [
        "### Pipeline Categório + Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D24yqg9wZSQX"
      },
      "outputs": [],
      "source": [
        "#Import do column transform\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V42BlUI5Y6v3"
      },
      "outputs": [],
      "source": [
        "#Seleção das variáveis numéricas, categóricas numéricas e categóricas.\n",
        "num_attr = list(df_float_64.columns)\n",
        "cat_num_attr = list(df_orders_treatment_cat_num.columns)\n",
        "cat_attr = list(df_orders_treatment_cat.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1ShBayxD5SH"
      },
      "outputs": [],
      "source": [
        "#Criação do Full Pipeline\n",
        "full_pipeline = ColumnTransformer([\n",
        "    ('num', num_pipeline, num_attr),\n",
        "    ('cat_num', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_num_attr),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_attr)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09-tdMHYD6zg",
        "outputId": "3b32b1b9-de49-4729-ac68-71fbaaacbc45"
      },
      "outputs": [],
      "source": [
        "#Transformação dos dados através do full pipeline\n",
        "df_orders_prepared = full_pipeline.fit_transform(df_orders_treatment)\n",
        "df_orders_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ne4F-qeQt2c1",
        "outputId": "9a16b2f8-35fa-4ad0-99f0-71a6122a271b"
      },
      "outputs": [],
      "source": [
        "df_orders_treatment_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhXJcbXCEnD0"
      },
      "source": [
        "#Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDiea17RoK3F"
      },
      "source": [
        "##SGDClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3_ApDTOERBc"
      },
      "source": [
        "O SGDClassifier (Stochastic Gradient Descent Classifier) é um algoritmo de aprendizado supervisionado, principalmente usado para tarefas de classificação, mas também pode ser aplicado para regressão. Ele é parte da biblioteca scikit-learn e é especialmente útil em problemas de aprendizado com grandes volumes de dados, pois realiza atualizações de parâmetros gradualmente em vez de carregar todo o conjunto de dados na memória de uma só vez.\n",
        "\n",
        "### **SGDClassifier: Fórmulas e Explicação**\n",
        "\n",
        "O `SGDClassifier` aplica o Gradiente Estocástico para minimizar uma função de custo associada ao modelo escolhido, como a **SVM Linear** ou a **Regressão Logística**.\n",
        "\n",
        "### 1. SVM Linear (Função de Custo Hinge)\n",
        "\n",
        "Para uma SVM Linear, o `SGDClassifier` minimiza a função de custo **hinge**, que maximiza a margem entre as classes:\n",
        "\n",
        "$$\n",
        "L(w, b) = \\frac{1}{n} \\sum_{i=1}^n \\max(0, 1 - y_i (w \\cdot x_i + b)) + \\frac{\\alpha}{2} \\|w\\|^2\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $( w $): vetor de pesos (ou coeficientes) do modelo.\n",
        "- $( b $): bias (intercepto).\n",
        "- $( x_i $): vetor de características da amostra $( i $).\n",
        "- $( y_i $): rótulo verdadeiro da amostra $( i $) (normalmente +1 ou -1 para SVM).\n",
        "- $( n $): número de amostras no lote.\n",
        "- $( \\alpha $): parâmetro de regularização, que controla o impacto da penalidade $( \\|w\\|^2 $) para evitar overfitting.\n",
        "\n",
        "A função hinge aplica uma penalidade apenas para amostras que estão incorretamente classificadas ou muito próximas da margem de decisão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "is9eFDbXtt6X",
        "outputId": "719c024d-978c-4656-cc1d-2bd135c2d158"
      },
      "outputs": [],
      "source": [
        "#import do SGDCLassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "#Treinamento do Modelo\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(df_orders_prepared, df_orders_treatment_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay-biCzpun6u"
      },
      "outputs": [],
      "source": [
        "#Seleciona os 10 primeiros registros de dados e labels\n",
        "dados = df_orders_treatment.iloc[:10]\n",
        "labels = df_orders_treatment_label.iloc[:10]\n",
        "\n",
        "#Passa pelo full pipeline\n",
        "dados_preparados = full_pipeline.transform(dados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fQ3FzjRuQkN",
        "outputId": "d3a89ddc-d0c4-4ffc-afc7-15fb51009cad"
      },
      "outputs": [],
      "source": [
        "#Realiza a predição dos valores\n",
        "sgd_clf.predict(dados_preparados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itdSC9m-uvF_",
        "outputId": "aa5c7f37-e4d1-4a32-cecc-24d54c926268"
      },
      "outputs": [],
      "source": [
        "#Verifica as Labels\n",
        "labels.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apatplX3G54O"
      },
      "source": [
        "### Validação Cruzada (cross_val_score)\n",
        "\n",
        "Utilizamos o cross_val_score em problemas de classificação para obter uma avaliação mais robusta e confiável do desempenho do modelo. Ele realiza a validação cruzada, que divide o conjunto de dados em múltiplos subconjuntos (ou folds) e testa o modelo em diferentes partições dos dados, ajudando a verificar a capacidade de generalização do modelo para dados novos.\n",
        "\n",
        "**A Validação Cruzada Reduz o Overfitting**: Em vez de treinar e testar o modelo em uma única divisão dos dados, a validação cruzada usa várias divisões, minimizando o risco de overfitting. Com isso, evitamos ajustar o modelo apenas a uma fração específica dos dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO8tKwhGu1BQ",
        "outputId": "e66b87d1-2811-4ad2-a187-591048d24b08"
      },
      "outputs": [],
      "source": [
        "#import do cross_val_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#Realiza o cross validation com 3 folds e orientado pela \"accuracy\"\n",
        "cross_val_score(sgd_clf, df_orders_prepared, df_orders_treatment_label, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fAjYYp2HmQD"
      },
      "source": [
        "### Validação Cruzada de Predição\n",
        "\n",
        "O cross_val_predict também utiliza a validação cruzada, mas, em vez de retornar uma pontuação média como o cross_val_score, ele gera diretamente as predições do modelo para cada amostra do conjunto de dados.\n",
        "\n",
        "Em resumo, o cross_val_predict é útil quando queremos:\n",
        "\n",
        "**Obter Predições de Validação Cruzada:** Ele retorna uma matriz com as predições do modelo para cada amostra no conjunto de dados, permitindo que analisemos o desempenho do modelo em nível de amostra.\n",
        "\n",
        "**Análise Detalhada de Métricas:** Como temos as predições para cada amostra, podemos calcular métricas como precisão, recall, F1-score, curva ROC e AUC, utilizando todas as amostras do conjunto de dados como se fossem dados de teste, sem afetar o processo de treino.\n",
        "\n",
        "**Redução de Overfitting em Métricas de Avaliação:** Calculando as métricas a partir das predições feitas por cross_val_predict, conseguimos uma avaliação mais próxima de um cenário real, onde cada predição foi feita com dados de treino diferentes dos dados de teste, evitando o uso de um conjunto fixo de treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usfjgGFRvQDm",
        "outputId": "f3daad3c-6f79-4508-85b4-0f59da61e282"
      },
      "outputs": [],
      "source": [
        "#import do cross_val_predict\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "#realiza a predição através do cross_val_predict\n",
        "y_train_pred = cross_val_predict(sgd_clf, df_orders_prepared, df_orders_treatment_label, cv=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "198BTiuvINti"
      },
      "source": [
        "### Matriz de Confusão\n",
        "\n",
        "A matriz de confusão é uma ferramenta muito útil para avaliar o desempenho de um modelo de classificação. Ela mostra, em uma tabela, as predições feitas pelo modelo versus os valores reais, ajudando a identificar erros específicos em cada classe e a entender onde o modelo está acertando ou errando.\n",
        "\n",
        "**Estrutura da Matriz de Confusão**\n",
        "Para um problema de classificação binária, a matriz de confusão é normalmente organizada da seguinte forma:\n",
        "\n",
        "\n",
        "\\begin{array}{|c|c|c|}\n",
        "\\hline\n",
        " & \\text{Previsão Positiva} & \\text{Previsão Negativa} \\\\\n",
        "\\hline\n",
        "\\text{Classe Positiva} & \\text{True Positive (TP)} & \\text{False Negative (FN)} \\\\\n",
        "\\hline\n",
        "\\text{Classe Negativa} & \\text{False Positive (FP)} & \\text{True Negative (TN)} \\\\\n",
        "\\hline\n",
        "\\end{array}\n",
        "\n",
        "### Componentes da Matriz de Confusão\n",
        "\n",
        "1. **True Positive (TP)**: Amostras corretamente classificadas como positivas.\n",
        "2. **False Positive (FP)**: Amostras negativas incorretamente classificadas como positivas (**falso alarme**).\n",
        "3. **True Negative (TN)**: Amostras corretamente classificadas como negativas.\n",
        "4. **False Negative (FN)**: Amostras positivas incorretamente classificadas como negativas (**falta de detecção**).\n",
        "\n",
        "#### Métricas Derivadas da Matriz de Confusão\n",
        "\n",
        "A partir dos valores de TP, FP, TN e FN, podemos calcular várias métricas para avaliar o modelo:\n",
        "\n",
        "1. **Acurácia**: Percentual de predições corretas em relação ao total de amostras.\n",
        "   $\n",
        "   \\text{Acurácia} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "   $\n",
        "\n",
        "2. **Precisão**: Percentual de predições positivas que são realmente positivas.\n",
        "   $\n",
        "   \\text{Precisão} = \\frac{TP}{TP + FP}\n",
        "   $\n",
        "\n",
        "3. **Recall (ou Sensibilidade)**: Percentual de amostras positivas corretamente identificadas.\n",
        "   $\n",
        "   \\text{Recall} = \\frac{TP}{TP + FN}\n",
        "   $\n",
        "\n",
        "4. **F1-Score**: Média harmônica entre precisão e recall, útil quando as classes são desbalanceadas.\n",
        "   $\n",
        "   F1 = 2 \\times \\frac{\\text{Precisão} \\times \\text{Recall}}{\\text{Precisão} + \\text{Recall}}\n",
        "   $\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT711UlHvnpB",
        "outputId": "17a7b707-504a-487c-d321-96d212262f4b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(df_orders_treatment_label, y_train_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YiJ57QZJgfP"
      },
      "source": [
        "### Classification Report\n",
        "\n",
        "O `classification_report` do `sklearn` gera um relatório com métricas de desempenho de um modelo de classificação para cada classe, facilitando a análise e comparação do desempenho entre classes.\n",
        "\n",
        "## Principais Métricas do `classification_report`\n",
        "\n",
        "1. **Acurácia**: Percentual de predições corretas em relação ao total de amostras.\n",
        "   $\n",
        "   \\text{Acurácia} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "   $\n",
        "\n",
        "\n",
        "2. **Precisão (Precision)**:\n",
        "   - A precisão indica a porcentagem de predições positivas que são realmente positivas.\n",
        "   - Fórmula:\n",
        "     $\n",
        "      \\text{Precisão} = \\frac{TP}{TP + FP}\n",
        "      $\n",
        "\n",
        "3. **Recall (Sensibilidade)**:\n",
        "   - O recall mede a capacidade do modelo de identificar corretamente todas as amostras da classe positiva.\n",
        "   - Fórmula:\n",
        "     $\n",
        "   \\text{Recall} = \\frac{TP}{TP + FN}\n",
        "   $\n",
        "\n",
        "4. **F1-Score**:\n",
        "   - O F1-Score é a média harmônica entre precisão e recall, útil quando temos classes desbalanceadas.\n",
        "   - Fórmula:\n",
        "     $\n",
        "   F1 = 2 \\times \\frac{\\text{Precisão} \\times \\text{Recall}}{\\text{Precisão} + \\text{Recall}}\n",
        "   $\n",
        "\n",
        "5. **Suporte (Support)**:\n",
        "   - O suporte é o número de ocorrências reais de cada classe no conjunto de dados, ajudando a avaliar o impacto de cada classe no cálculo das métricas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1dPry-yv5JC",
        "outputId": "554a9751-fda1-4cdb-bfd0-632bcb155a6d"
      },
      "outputs": [],
      "source": [
        "#import do classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "#realizada o classification report\n",
        "report = classification_report(df_orders_treatment_label, y_train_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ylDq3xDhrDYM",
        "outputId": "6ee78bd6-623b-44ff-fe68-d4e15407a194"
      },
      "outputs": [],
      "source": [
        "#Analisa a porcentagem entre status\n",
        "df_orders_treatment_label['order_status'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEY96EaCLZqH"
      },
      "source": [
        "### Desbalanceamento entre Classes\n",
        "\n",
        "O desbalanceamento de classes pode afetar negativamente o desempenho de modelos de machine learning, pois o modelo pode aprender a favorecer a classe majoritária, ignorando as amostras da classe minoritária. Essas são umas das principais estratégias para lidar com classes desbalanceadas:\n",
        "\n",
        "####Oversampling\n",
        "O oversampling consiste em aumentar a quantidade de instâncias da classe minoritária, de forma que ela tenha uma representação mais equilibrada em relação à classe majoritária. O método mais simples de oversampling é a duplicação de dados da classe minoritária, mas isso pode levar a overfitting.\n",
        "\n",
        "####Undersampling\n",
        "O undersampling é o processo de reduzir a quantidade de instâncias da classe majoritária, diminuindo o número de amostras para equilibrá-lo com a classe minoritária. A técnica mais simples de undersampling é a remoção aleatória de instâncias da classe majoritária. No entanto, isso pode resultar na perda de informações importantes, principalmente se o conjunto de dados for pequeno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwVfhFzEoO0n"
      },
      "source": [
        "## SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "O SMOTE é uma técnica de oversampling que cria novas instâncias sintéticas da classe minoritária em vez de duplicar instâncias. Ele funciona da seguinte maneira:\n",
        "\n",
        "Para cada instância da classe minoritária, o SMOTE seleciona uma ou mais instâncias vizinhas próximas.\n",
        "Novas instâncias são geradas interpolando os atributos entre a instância original e a vizinha selecionada.\n",
        "Esse processo ajuda a evitar o overfitting, pois as novas amostras são únicas e não cópias diretas das amostras existentes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csqwFAIPrXtR"
      },
      "outputs": [],
      "source": [
        "#import do SMOTE\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUQiwWgJreEH"
      },
      "outputs": [],
      "source": [
        "# criando uma instância do SMOTE\n",
        "smote = SMOTE()\n",
        "\n",
        "# balanceando os dados\n",
        "X_resampled, y_resampled = smote.fit_resample(df_orders_prepared, df_orders_treatment_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "zwuBxAQlrkCX",
        "outputId": "c19843da-d510-4568-de8d-b6ce349030fa"
      },
      "outputs": [],
      "source": [
        "#Análise entre status\n",
        "y_resampled['order_status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "R3LIapzLs9Hx",
        "outputId": "5a9ef9ff-c2ef-4451-ba90-da86af176397"
      },
      "outputs": [],
      "source": [
        "#Realizando o treino novamente com o SGDClassifier\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_resampled, y_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n33wOagtPwR",
        "outputId": "ba8e6508-7de0-4f8d-ce54-6ed1d3f2bcd7"
      },
      "outputs": [],
      "source": [
        "#Realizando a validação cruzada orientada a previsão pelo resampling do SMOTE\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_resampled, y_resampled, cv=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BvFRc0CtYRJ",
        "outputId": "5a9add22-5201-45f0-a664-1f179af5330b"
      },
      "outputs": [],
      "source": [
        "#Análise do classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_resampled, y_train_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUncjEI2oDVn"
      },
      "source": [
        "## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEfJb9m6n8b1"
      },
      "outputs": [],
      "source": [
        "#Import do RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "fWbsvu_1n-s_",
        "outputId": "ac829538-6452-4ba6-9909-e890d6d0b067"
      },
      "outputs": [],
      "source": [
        "#Treina o modelo no RandomForestClassifier\n",
        "forest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "forest_clf.fit(X_resampled, y_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwaO-zXFrdYo",
        "outputId": "ff465c4d-2718-4402-ade0-48e18ab8e44c"
      },
      "outputs": [],
      "source": [
        "#Realiza a Validação Cruzada\n",
        "y_train_pred = cross_val_predict(forest_clf, X_resampled, y_resampled, cv=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-SfFKr_qXk4",
        "outputId": "02cc66da-c8ff-4a9e-c8fc-6a011b7ce40b"
      },
      "outputs": [],
      "source": [
        "#Print do Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_resampled, y_train_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD72sszdM1EI"
      },
      "source": [
        "### Modelo de Classificação Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FrlWOb8sbNw"
      },
      "outputs": [],
      "source": [
        "#Escolhe o modelo\n",
        "final_model = forest_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pHWWMRasbNx"
      },
      "outputs": [],
      "source": [
        "#Seleciona o dataset de teste\n",
        "df_orders_test = test_set.copy()\n",
        "x_test = df_orders_test.drop('order_status', axis=1)\n",
        "y_test = df_orders_test['order_status'].copy()\n",
        "\n",
        "#Faz o tratamento dos dados\n",
        "x_test_prepared = full_pipeline.transform(x_test)\n",
        "final_predictions = final_model.predict(x_test_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz6OkkBtsbNx",
        "outputId": "a296f478-63f0-423c-ea9a-c926c3f51fd7"
      },
      "outputs": [],
      "source": [
        "#Analise do classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, final_predictions)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
